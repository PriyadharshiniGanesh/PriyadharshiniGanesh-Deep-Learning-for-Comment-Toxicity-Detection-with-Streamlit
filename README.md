# PriyadharshiniGanesh-Deep-Learning-for-Comment-Toxicity-Detection-with-Streamlit

Intoduction:
Online communities and social media platforms have become integral parts of modern communication, facilitating interactions and discussions on various topics. However, the prevalence of toxic comments, which include harassment, hate speech, and offensive language, poses significant challenges to maintaining healthy and constructive online discourse. It encompasses various forms, including hate speech, personal attacks, bullying, and insults. 
To address this issue, there is a pressing need for automated systems capable of detecting and flagging toxic comments in real-time. The objective of this project is to develop a deep learning-based comment toxicity model using Python.

Approach:
1.  Data Exploration and Preparation
2.  Model Development
3.  Streamlit Application Development
Dataset:
The data contains these types of toxicity:
•	toxic
•	severe_toxic
•	obscene
•	threat
•	insult
•	identity_hate
You must create a model which predicts a probability of each type of toxicity for each comment.

File descriptions
•	train.csv - the training set, contains comments with their binary labels
•	test.csv - the test set, you must predict the toxicity probabilities for these comments. To deter hand labeling, the test set contains some comments which are not included in scoring.
•	sample_submission.csv - a sample submission file in the correct format

Technologies
Python, Deep Learning, Neural Networks, NLP, Model Training, Model Evaluation, Streamlit, Model Deployment
![Screenshot 2025-06-08 194907](https://github.com/user-attachments/assets/a02e4561-58b1-435b-b83e-1e86dc7f8687)
